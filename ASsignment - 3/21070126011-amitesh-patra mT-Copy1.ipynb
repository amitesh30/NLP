{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME - AMITESH PATRA \n",
    "BATCH - AIML A1\n",
    "PRN - 21070126011\n",
    "github - https://github.com/amitesh30/NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense,Input, Embedding\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Hindi_English_Truncated_Corpus.csv',encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting sources\n",
    "data['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selcting data with source ted\n",
    "data = data[data.source == 'tides']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:22.658008Z",
     "iopub.status.busy": "2023-09-24T03:42:22.657690Z",
     "iopub.status.idle": "2023-09-24T03:42:22.679173Z",
     "shell.execute_reply": "2023-09-24T03:42:22.678090Z",
     "shell.execute_reply.started": "2023-09-24T03:42:22.657983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:22.682038Z",
     "iopub.status.busy": "2023-09-24T03:42:22.680984Z",
     "iopub.status.idle": "2023-09-24T03:42:22.798514Z",
     "shell.execute_reply": "2023-09-24T03:42:22.796674Z",
     "shell.execute_reply.started": "2023-09-24T03:42:22.682004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows are:  1078\n"
     ]
    }
   ],
   "source": [
    "# checking duplicated data\n",
    "isDuplicated = data.duplicated().any()\n",
    "if isDuplicated:\n",
    "    total_duplicates = data.duplicated().sum()\n",
    "    print(\"Total duplicate rows are: \",total_duplicates)\n",
    "    data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:22.818435Z",
     "iopub.status.busy": "2023-09-24T03:42:22.818169Z",
     "iopub.status.idle": "2023-09-24T03:42:22.918685Z",
     "shell.execute_reply": "2023-09-24T03:42:22.917729Z",
     "shell.execute_reply.started": "2023-09-24T03:42:22.818412Z"
    }
   },
   "outputs": [],
   "source": [
    "## changing uppercase to lowercase\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.lower())\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:22.920321Z",
     "iopub.status.busy": "2023-09-24T03:42:22.919980Z",
     "iopub.status.idle": "2023-09-24T03:42:23.201057Z",
     "shell.execute_reply": "2023-09-24T03:42:23.200016Z",
     "shell.execute_reply.started": "2023-09-24T03:42:22.920290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuations to exclude::  {'>', '&', '~', '`', '!', \"'\", ';', '^', '/', ')', '#', '+', '-', '\\\\', '|', '{', '_', ',', '.', ']', '?', '%', '}', '@', '<', '$', ':', '=', '\"', '(', '*', '['}\n"
     ]
    }
   ],
   "source": [
    "to_exclude = set(string.punctuation) # Set of all special characters\n",
    "print(\"punctuations to exclude:: \",to_exclude)\n",
    "# Remove all the special characters\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.203017Z",
     "iopub.status.busy": "2023-09-24T03:42:23.202362Z",
     "iopub.status.idle": "2023-09-24T03:42:23.580727Z",
     "shell.execute_reply": "2023-09-24T03:42:23.579747Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.202981Z"
    }
   },
   "outputs": [],
   "source": [
    "from string import digits\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.582648Z",
     "iopub.status.busy": "2023-09-24T03:42:23.582296Z",
     "iopub.status.idle": "2023-09-24T03:42:23.598697Z",
     "shell.execute_reply": "2023-09-24T03:42:23.597762Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.582615Z"
    }
   },
   "outputs": [],
   "source": [
    "## adding start and end token to the target sentence\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: \"START_ \" + x + \" _END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.600705Z",
     "iopub.status.busy": "2023-09-24T03:42:23.599904Z",
     "iopub.status.idle": "2023-09-24T03:42:23.668754Z",
     "shell.execute_reply": "2023-09-24T03:42:23.667696Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.600671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>english_length</th>\n",
       "      <th>hindi_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123152</th>\n",
       "      <td>ted</td>\n",
       "      <td>is not about belief but about behavior</td>\n",
       "      <td>START_ वो विश्वास के बारे में नहीं वरन लेकिन व...</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31468</th>\n",
       "      <td>ted</td>\n",
       "      <td>than the story were going to tell about it later</td>\n",
       "      <td>START_ उससे जो हम बाद में बताने वाले हैं _END</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102720</th>\n",
       "      <td>ted</td>\n",
       "      <td>and if they need a pair of glasses they are av...</td>\n",
       "      <td>START_ यदि किसी को चश्मे की ज़रूरत है तो उसे श...</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40273</th>\n",
       "      <td>ted</td>\n",
       "      <td>the feedback here is immediate</td>\n",
       "      <td>START_ यहाँ तुरंत नतीजा मिलता है _END</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17027</th>\n",
       "      <td>ted</td>\n",
       "      <td>a rather astonishing demonstration of the abil...</td>\n",
       "      <td>START_ यह दिमाग की एक अद्भुत क्षमता का प्रदर्श...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "123152    ted             is not about belief but about behavior   \n",
       "31468     ted   than the story were going to tell about it later   \n",
       "102720    ted  and if they need a pair of glasses they are av...   \n",
       "40273     ted                     the feedback here is immediate   \n",
       "17027     ted  a rather astonishing demonstration of the abil...   \n",
       "\n",
       "                                           hindi_sentence  english_length  \\\n",
       "123152  START_ वो विश्वास के बारे में नहीं वरन लेकिन व...               7   \n",
       "31468       START_ उससे जो हम बाद में बताने वाले हैं _END              10   \n",
       "102720  START_ यदि किसी को चश्मे की ज़रूरत है तो उसे श...              17   \n",
       "40273               START_ यहाँ तुरंत नतीजा मिलता है _END               5   \n",
       "17027   START_ यह दिमाग की एक अद्भुत क्षमता का प्रदर्श...              10   \n",
       "\n",
       "        hindi_length  \n",
       "123152            14  \n",
       "31468             10  \n",
       "102720            19  \n",
       "40273              7  \n",
       "17027             11  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## counting length of english and hindi sentence\n",
    "data['english_length'] = data['english_sentence'].apply(lambda x: len(x.split(' ')))\n",
    "data['hindi_length'] = data['hindi_sentence'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.670807Z",
     "iopub.status.busy": "2023-09-24T03:42:23.669953Z",
     "iopub.status.idle": "2023-09-24T03:42:23.683159Z",
     "shell.execute_reply": "2023-09-24T03:42:23.682019Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.670751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of English Sentence:  21\n",
      "Maximum length of Hindi Sentence:  32\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of English Sentence: \", max(data['english_length']))\n",
    "print(\"Maximum length of Hindi Sentence: \",max(data['hindi_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.688957Z",
     "iopub.status.busy": "2023-09-24T03:42:23.688658Z",
     "iopub.status.idle": "2023-09-24T03:42:23.802406Z",
     "shell.execute_reply": "2023-09-24T03:42:23.801430Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.688933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toral english words:  12483\n",
      "total hind words:  15529\n"
     ]
    }
   ],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in data['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in data['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)\n",
    "            \n",
    "\n",
    "print(\"toral english words: \",len(all_eng_words))\n",
    "print('total hind words: ',len(all_hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.804488Z",
     "iopub.status.busy": "2023-09-24T03:42:23.803849Z",
     "iopub.status.idle": "2023-09-24T03:42:23.820319Z",
     "shell.execute_reply": "2023-09-24T03:42:23.819125Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.804452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19830, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using only sentence with length less than 20\n",
    "mask1 = data['english_length'] < 21\n",
    "mask2 = data['hindi_length'] < 21\n",
    "data = data[mask1 & mask2]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.823497Z",
     "iopub.status.busy": "2023-09-24T03:42:23.822913Z",
     "iopub.status.idle": "2023-09-24T03:42:23.836073Z",
     "shell.execute_reply": "2023-09-24T03:42:23.834938Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.823463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(data['hindi_length']))\n",
    "print(\"maximum length of English Sentence \",max(data['english_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.838179Z",
     "iopub.status.busy": "2023-09-24T03:42:23.837724Z",
     "iopub.status.idle": "2023-09-24T03:42:23.868019Z",
     "shell.execute_reply": "2023-09-24T03:42:23.867075Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.838143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12483, 15529)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.870163Z",
     "iopub.status.busy": "2023-09-24T03:42:23.869360Z",
     "iopub.status.idle": "2023-09-24T03:42:23.878244Z",
     "shell.execute_reply": "2023-09-24T03:42:23.877282Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.870127Z"
    }
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.880228Z",
     "iopub.status.busy": "2023-09-24T03:42:23.879891Z",
     "iopub.status.idle": "2023-09-24T03:42:23.902121Z",
     "shell.execute_reply": "2023-09-24T03:42:23.900862Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.880197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token for accelerating is:  50\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "print(\"Token for accelerating is: \",input_token_index['accelerating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.905032Z",
     "iopub.status.busy": "2023-09-24T03:42:23.903515Z",
     "iopub.status.idle": "2023-09-24T03:42:23.922612Z",
     "shell.execute_reply": "2023-09-24T03:42:23.921565Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.904996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character for toker 50 is:  accelerating\n"
     ]
    }
   ],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "print(\"Character for toker 50 is: \",reverse_input_char_index[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.924650Z",
     "iopub.status.busy": "2023-09-24T03:42:23.924298Z",
     "iopub.status.idle": "2023-09-24T03:42:23.939686Z",
     "shell.execute_reply": "2023-09-24T03:42:23.938779Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.924618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training data:  15864\n",
      "Toral number of testing data:  3966\n"
     ]
    }
   ],
   "source": [
    "# splitting data\n",
    "X_, y_ = data['english_sentence'], data['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2,random_state=42)\n",
    "print(\"Total number of training data: \",X_train.shape[0])\n",
    "print(\"Toral number of testing data: \",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:23.941888Z",
     "iopub.status.busy": "2023-09-24T03:42:23.941471Z",
     "iopub.status.idle": "2023-09-24T03:42:31.165603Z",
     "shell.execute_reply": "2023-09-24T03:42:31.164844Z",
     "shell.execute_reply.started": "2023-09-24T03:42:23.941855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 300)    3744900     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, None, 300),  721200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 300)    4659000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 300),        721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  721200      ['lstm_2[0][0]',                 \n",
      "                                 (None, 300),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 15530)  4674530     ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,963,230\n",
      "Trainable params: 15,963,230\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)\n",
    "\n",
    "# Concatenate the states from both LSTM layers\n",
    "encoder_states = [state_h2, state_c2]\n",
    "\n",
    "# Set up the decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs1, _, _ = decoder_lstm1(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs1, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:31.167361Z",
     "iopub.status.busy": "2023-09-24T03:42:31.166697Z",
     "iopub.status.idle": "2023-09-24T03:42:31.173222Z",
     "shell.execute_reply": "2023-09-24T03:42:31.172452Z",
     "shell.execute_reply.started": "2023-09-24T03:42:31.167326Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:31.174583Z",
     "iopub.status.busy": "2023-09-24T03:42:31.174229Z",
     "iopub.status.idle": "2023-09-24T03:42:31.219592Z",
     "shell.execute_reply": "2023-09-24T03:42:31.218883Z",
     "shell.execute_reply.started": "2023-09-24T03:42:31.174551Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001, epsilon=1e-7), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:31.221596Z",
     "iopub.status.busy": "2023-09-24T03:42:31.220871Z",
     "iopub.status.idle": "2023-09-24T03:42:31.232568Z",
     "shell.execute_reply": "2023-09-24T03:42:31.231427Z",
     "shell.execute_reply.started": "2023-09-24T03:42:31.221563Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length_src = 20\n",
    "max_length_tar = 20 \n",
    "\n",
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:31.236590Z",
     "iopub.status.busy": "2023-09-24T03:42:31.235608Z",
     "iopub.status.idle": "2023-09-24T03:42:31.246875Z",
     "shell.execute_reply": "2023-09-24T03:42:31.246153Z",
     "shell.execute_reply.started": "2023-09-24T03:42:31.236556Z"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T03:42:31.249251Z",
     "iopub.status.busy": "2023-09-24T03:42:31.248975Z",
     "iopub.status.idle": "2023-09-24T04:58:24.057041Z",
     "shell.execute_reply": "2023-09-24T04:58:24.056083Z",
     "shell.execute_reply.started": "2023-09-24T03:42:31.249206Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29/2108290721.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123/123 [==============================] - 92s 574ms/step - loss: 6.8924 - accuracy: 0.1200 - val_loss: 6.5331 - val_accuracy: 0.1275\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 44s 357ms/step - loss: 6.3666 - accuracy: 0.1313 - val_loss: 6.5401 - val_accuracy: 0.1290\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 46s 374ms/step - loss: 6.3009 - accuracy: 0.1327 - val_loss: 6.4936 - val_accuracy: 0.1309\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 6.1550 - accuracy: 0.1368 - val_loss: 6.2743 - val_accuracy: 0.1427\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 43s 354ms/step - loss: 5.8717 - accuracy: 0.1496 - val_loss: 6.1069 - val_accuracy: 0.1517\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 5.6580 - accuracy: 0.1677 - val_loss: 6.0047 - val_accuracy: 0.1694\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 45s 369ms/step - loss: 5.4802 - accuracy: 0.1863 - val_loss: 5.9380 - val_accuracy: 0.1785\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 5.3337 - accuracy: 0.1986 - val_loss: 5.8928 - val_accuracy: 0.1843\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 44s 354ms/step - loss: 5.1881 - accuracy: 0.2079 - val_loss: 5.8481 - val_accuracy: 0.1873\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 5.0424 - accuracy: 0.2192 - val_loss: 5.7961 - val_accuracy: 0.1963\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 45s 371ms/step - loss: 4.9117 - accuracy: 0.2309 - val_loss: 5.7986 - val_accuracy: 0.2016\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 4.7979 - accuracy: 0.2387 - val_loss: 5.7890 - val_accuracy: 0.2066\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 4.6916 - accuracy: 0.2458 - val_loss: 5.7809 - val_accuracy: 0.2085\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 45s 369ms/step - loss: 4.5883 - accuracy: 0.2535 - val_loss: 5.8057 - val_accuracy: 0.2112\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 45s 369ms/step - loss: 4.4878 - accuracy: 0.2602 - val_loss: 5.8832 - val_accuracy: 0.2128\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 4.3989 - accuracy: 0.2662 - val_loss: 5.8277 - val_accuracy: 0.2144\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 43s 353ms/step - loss: 4.3060 - accuracy: 0.2734 - val_loss: 5.8441 - val_accuracy: 0.2168\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 45s 370ms/step - loss: 4.2078 - accuracy: 0.2798 - val_loss: 5.8462 - val_accuracy: 0.2158\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 45s 363ms/step - loss: 4.1081 - accuracy: 0.2869 - val_loss: 5.8557 - val_accuracy: 0.2163\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 45s 370ms/step - loss: 4.0147 - accuracy: 0.2940 - val_loss: 5.8614 - val_accuracy: 0.2197\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 3.9259 - accuracy: 0.3010 - val_loss: 5.8877 - val_accuracy: 0.2168\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 43s 352ms/step - loss: 3.8511 - accuracy: 0.3078 - val_loss: 5.9200 - val_accuracy: 0.2171\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 3.7658 - accuracy: 0.3163 - val_loss: 5.9297 - val_accuracy: 0.2208\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 3.6771 - accuracy: 0.3264 - val_loss: 5.9471 - val_accuracy: 0.2210\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 3.5855 - accuracy: 0.3390 - val_loss: 6.0035 - val_accuracy: 0.2202\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 44s 358ms/step - loss: 3.5015 - accuracy: 0.3503 - val_loss: 5.9884 - val_accuracy: 0.2203\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 3.4228 - accuracy: 0.3605 - val_loss: 6.0223 - val_accuracy: 0.2215\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 45s 366ms/step - loss: 3.3431 - accuracy: 0.3717 - val_loss: 6.0555 - val_accuracy: 0.2234\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 45s 368ms/step - loss: 3.2588 - accuracy: 0.3823 - val_loss: 6.0770 - val_accuracy: 0.2210\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 47s 379ms/step - loss: 3.1874 - accuracy: 0.3933 - val_loss: 6.1227 - val_accuracy: 0.2215\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 46s 375ms/step - loss: 3.1309 - accuracy: 0.4024 - val_loss: 6.1377 - val_accuracy: 0.2237\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 44s 360ms/step - loss: 3.0428 - accuracy: 0.4140 - val_loss: 6.1514 - val_accuracy: 0.2227\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 47s 378ms/step - loss: 2.9591 - accuracy: 0.4269 - val_loss: 6.1770 - val_accuracy: 0.2198\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 46s 378ms/step - loss: 2.8757 - accuracy: 0.4407 - val_loss: 6.2190 - val_accuracy: 0.2190\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 46s 377ms/step - loss: 2.7989 - accuracy: 0.4525 - val_loss: 6.2775 - val_accuracy: 0.2181\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 2.7314 - accuracy: 0.4618 - val_loss: 6.3076 - val_accuracy: 0.2173\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 46s 377ms/step - loss: 2.6635 - accuracy: 0.4740 - val_loss: 6.3462 - val_accuracy: 0.2169\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 2.6024 - accuracy: 0.4833 - val_loss: 6.3913 - val_accuracy: 0.2232\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 47s 384ms/step - loss: 2.5419 - accuracy: 0.4931 - val_loss: 6.4301 - val_accuracy: 0.2199\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 45s 370ms/step - loss: 2.4741 - accuracy: 0.5050 - val_loss: 6.4473 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 47s 379ms/step - loss: 2.4112 - accuracy: 0.5164 - val_loss: 6.5238 - val_accuracy: 0.2183\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 47s 379ms/step - loss: 2.3490 - accuracy: 0.5279 - val_loss: 6.6147 - val_accuracy: 0.2215\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 46s 378ms/step - loss: 2.2916 - accuracy: 0.5369 - val_loss: 6.6324 - val_accuracy: 0.2164\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 46s 378ms/step - loss: 2.2312 - accuracy: 0.5477 - val_loss: 6.6189 - val_accuracy: 0.2107\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 46s 379ms/step - loss: 2.1750 - accuracy: 0.5577 - val_loss: 6.6465 - val_accuracy: 0.2131\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 46s 376ms/step - loss: 2.1173 - accuracy: 0.5684 - val_loss: 6.6696 - val_accuracy: 0.2128\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 44s 361ms/step - loss: 2.0577 - accuracy: 0.5799 - val_loss: 6.7097 - val_accuracy: 0.2159\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 44s 359ms/step - loss: 1.9956 - accuracy: 0.5909 - val_loss: 6.7772 - val_accuracy: 0.2160\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 45s 364ms/step - loss: 1.9392 - accuracy: 0.6017 - val_loss: 6.7784 - val_accuracy: 0.2135\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 44s 357ms/step - loss: 1.8830 - accuracy: 0.6127 - val_loss: 6.8402 - val_accuracy: 0.2097\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 1.8280 - accuracy: 0.6233 - val_loss: 6.9179 - val_accuracy: 0.2105\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 44s 359ms/step - loss: 1.7784 - accuracy: 0.6331 - val_loss: 6.9240 - val_accuracy: 0.2049\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 46s 375ms/step - loss: 1.7263 - accuracy: 0.6427 - val_loss: 6.9797 - val_accuracy: 0.2044\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 1.6739 - accuracy: 0.6534 - val_loss: 7.0709 - val_accuracy: 0.2079\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 1.6218 - accuracy: 0.6637 - val_loss: 7.1302 - val_accuracy: 0.2035\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 1.5655 - accuracy: 0.6759 - val_loss: 7.2110 - val_accuracy: 0.2048\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 1.5147 - accuracy: 0.6866 - val_loss: 7.2086 - val_accuracy: 0.2075\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 1.4640 - accuracy: 0.6966 - val_loss: 7.2181 - val_accuracy: 0.2025\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 1.4154 - accuracy: 0.7070 - val_loss: 7.2832 - val_accuracy: 0.2078\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 45s 370ms/step - loss: 1.2678 - accuracy: 0.7401 - val_loss: 7.4047 - val_accuracy: 0.2006\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 47s 379ms/step - loss: 1.2250 - accuracy: 0.7490 - val_loss: 7.5097 - val_accuracy: 0.2052\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 46s 379ms/step - loss: 1.1811 - accuracy: 0.7590 - val_loss: 7.5975 - val_accuracy: 0.2076\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 46s 379ms/step - loss: 1.1402 - accuracy: 0.7678 - val_loss: 7.5935 - val_accuracy: 0.2043\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 44s 360ms/step - loss: 1.0996 - accuracy: 0.7761 - val_loss: 7.6354 - val_accuracy: 0.1961\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 44s 360ms/step - loss: 1.0571 - accuracy: 0.7853 - val_loss: 7.7630 - val_accuracy: 0.2055\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 1.0147 - accuracy: 0.7957 - val_loss: 7.7433 - val_accuracy: 0.1982\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 46s 374ms/step - loss: 0.9692 - accuracy: 0.8053 - val_loss: 7.7830 - val_accuracy: 0.1959\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 44s 356ms/step - loss: 0.9271 - accuracy: 0.8157 - val_loss: 7.9347 - val_accuracy: 0.2040\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 46s 374ms/step - loss: 0.8833 - accuracy: 0.8262 - val_loss: 7.9950 - val_accuracy: 0.2020\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 46s 377ms/step - loss: 0.8459 - accuracy: 0.8347 - val_loss: 7.9892 - val_accuracy: 0.1964\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 46s 374ms/step - loss: 0.8079 - accuracy: 0.8430 - val_loss: 8.0303 - val_accuracy: 0.1970\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 46s 377ms/step - loss: 0.7715 - accuracy: 0.8518 - val_loss: 8.0814 - val_accuracy: 0.1972\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 46s 375ms/step - loss: 0.7359 - accuracy: 0.8613 - val_loss: 8.1370 - val_accuracy: 0.1958\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.7017 - accuracy: 0.8696 - val_loss: 8.3113 - val_accuracy: 0.2031\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 0.6767 - accuracy: 0.8751 - val_loss: 8.4213 - val_accuracy: 0.2034\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 0.6415 - accuracy: 0.8821 - val_loss: 8.3667 - val_accuracy: 0.1964\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.6117 - accuracy: 0.8897 - val_loss: 8.3487 - val_accuracy: 0.1914\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 43s 354ms/step - loss: 0.5813 - accuracy: 0.8954 - val_loss: 8.3680 - val_accuracy: 0.1862\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 44s 357ms/step - loss: 0.5573 - accuracy: 0.9007 - val_loss: 8.4394 - val_accuracy: 0.1902\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 43s 352ms/step - loss: 0.5340 - accuracy: 0.9055 - val_loss: 8.5362 - val_accuracy: 0.1950\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.5051 - accuracy: 0.9122 - val_loss: 8.5421 - val_accuracy: 0.1875\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 43s 352ms/step - loss: 0.4741 - accuracy: 0.9198 - val_loss: 8.6279 - val_accuracy: 0.1854\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 0.4453 - accuracy: 0.9276 - val_loss: 8.7753 - val_accuracy: 0.1942\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 0.4163 - accuracy: 0.9345 - val_loss: 8.8584 - val_accuracy: 0.1965\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.3884 - accuracy: 0.9413 - val_loss: 8.7799 - val_accuracy: 0.1903\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.3672 - accuracy: 0.9455 - val_loss: 8.8244 - val_accuracy: 0.1865\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 0.3476 - accuracy: 0.9493 - val_loss: 8.8847 - val_accuracy: 0.1856\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 45s 371ms/step - loss: 0.3308 - accuracy: 0.9530 - val_loss: 8.9784 - val_accuracy: 0.1873\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 0.3167 - accuracy: 0.9554 - val_loss: 9.0788 - val_accuracy: 0.1939\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.3018 - accuracy: 0.9584 - val_loss: 9.1110 - val_accuracy: 0.1959\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 44s 357ms/step - loss: 0.2830 - accuracy: 0.9623 - val_loss: 9.1672 - val_accuracy: 0.1935\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 43s 354ms/step - loss: 0.2583 - accuracy: 0.9680 - val_loss: 9.2720 - val_accuracy: 0.1955\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 43s 353ms/step - loss: 0.2451 - accuracy: 0.9712 - val_loss: 9.2456 - val_accuracy: 0.1937\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 44s 358ms/step - loss: 0.2103 - accuracy: 0.9788 - val_loss: 9.2723 - val_accuracy: 0.1890\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 46s 372ms/step - loss: 0.1956 - accuracy: 0.9813 - val_loss: 9.3594 - val_accuracy: 0.1900\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 0.1748 - accuracy: 0.9856 - val_loss: 9.4831 - val_accuracy: 0.1915\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 0.1592 - accuracy: 0.9879 - val_loss: 9.5400 - val_accuracy: 0.1927\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 43s 353ms/step - loss: 0.1466 - accuracy: 0.9899 - val_loss: 9.5896 - val_accuracy: 0.1926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c50aff47d00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:05:55.342341Z",
     "iopub.status.busy": "2023-09-24T05:05:55.341960Z",
     "iopub.status.idle": "2023-09-24T05:05:55.348221Z",
     "shell.execute_reply": "2023-09-24T05:05:55.346916Z",
     "shell.execute_reply.started": "2023-09-24T05:05:55.342311Z"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:05:58.214578Z",
     "iopub.status.busy": "2023-09-24T05:05:58.214217Z",
     "iopub.status.idle": "2023-09-24T05:13:18.109690Z",
     "shell.execute_reply": "2023-09-24T05:13:18.108715Z",
     "shell.execute_reply.started": "2023-09-24T05:05:58.214549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29/2108290721.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 45s 368ms/step - loss: 0.1093 - accuracy: 0.9948 - val_loss: 9.6977 - val_accuracy: 0.1914\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 43s 351ms/step - loss: 0.1016 - accuracy: 0.9957 - val_loss: 9.7523 - val_accuracy: 0.1915\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 43s 353ms/step - loss: 0.0930 - accuracy: 0.9966 - val_loss: 9.7925 - val_accuracy: 0.1910\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 43s 348ms/step - loss: 0.0870 - accuracy: 0.9969 - val_loss: 9.8405 - val_accuracy: 0.1895\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 45s 369ms/step - loss: 0.0811 - accuracy: 0.9974 - val_loss: 9.9214 - val_accuracy: 0.1904\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 43s 350ms/step - loss: 0.0769 - accuracy: 0.9975 - val_loss: 9.9866 - val_accuracy: 0.1926\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 43s 349ms/step - loss: 0.0734 - accuracy: 0.9977 - val_loss: 9.9998 - val_accuracy: 0.1917\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 45s 368ms/step - loss: 0.0688 - accuracy: 0.9980 - val_loss: 10.0777 - val_accuracy: 0.1912\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 46s 371ms/step - loss: 0.0658 - accuracy: 0.9979 - val_loss: 10.1585 - val_accuracy: 0.1915\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 43s 351ms/step - loss: 0.0619 - accuracy: 0.9982 - val_loss: 10.1820 - val_accuracy: 0.1912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c4c147ce920>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:15.692091Z",
     "iopub.status.busy": "2023-09-24T05:17:15.691671Z",
     "iopub.status.idle": "2023-09-24T05:17:16.626757Z",
     "shell.execute_reply": "2023-09-24T05:17:16.625756Z",
     "shell.execute_reply.started": "2023-09-24T05:17:15.692060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\" \n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm2(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:16.629012Z",
     "iopub.status.busy": "2023-09-24T05:17:16.628599Z",
     "iopub.status.idle": "2023-09-24T05:17:16.634597Z",
     "shell.execute_reply": "2023-09-24T05:17:16.633699Z",
     "shell.execute_reply.started": "2023-09-24T05:17:16.628976Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:16.636904Z",
     "iopub.status.busy": "2023-09-24T05:17:16.636076Z",
     "iopub.status.idle": "2023-09-24T05:17:20.717881Z",
     "shell.execute_reply": "2023-09-24T05:17:20.716778Z",
     "shell.execute_reply.started": "2023-09-24T05:17:16.636870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input English sentence: which occurs in nature\n",
      "Actual Hindi Translation:  जो प्रकृति में होता है \n",
      "Predicted Hindi Translation:  जो जो जिसका हरी का किसी बिजली \n"
     ]
    }
   ],
   "source": [
    "\n",
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:20.722118Z",
     "iopub.status.busy": "2023-09-24T05:17:20.721823Z",
     "iopub.status.idle": "2023-09-24T05:17:21.541689Z",
     "shell.execute_reply": "2023-09-24T05:17:21.540767Z",
     "shell.execute_reply.started": "2023-09-24T05:17:20.722092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input English sentence: are actually going to matter in the long run\n",
      "Actual Hindi Translation:  लंबे समय में हमारे लिए मायने रखते है \n",
      "Predicted Hindi Translation:  उसमें वो बच्चों बच्चों जहाँ में जहाँ में में में\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:21.543254Z",
     "iopub.status.busy": "2023-09-24T05:17:21.542949Z",
     "iopub.status.idle": "2023-09-24T05:17:22.164315Z",
     "shell.execute_reply": "2023-09-24T05:17:22.162739Z",
     "shell.execute_reply.started": "2023-09-24T05:17:21.543227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input English sentence: i mean really though\n",
      "Actual Hindi Translation:  मेरा मतलब सच में कठिन \n",
      "Predicted Hindi Translation:  मेरा कहेता में गरीबी अलग या की \n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:22.166402Z",
     "iopub.status.busy": "2023-09-24T05:17:22.166031Z",
     "iopub.status.idle": "2023-09-24T05:17:23.081144Z",
     "shell.execute_reply": "2023-09-24T05:17:23.079948Z",
     "shell.execute_reply.started": "2023-09-24T05:17:22.166366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Input English sentence: and youre aware of how many people are around you\n",
      "Actual Hindi Translation:  और आपको अंदाज़ा है कि कितने लोग आपके आसपास है \n",
      "Predicted Hindi Translation:  और आप आपको आप आपको लेकिन आपको आपको लेकिन आपको हमे\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:23.084437Z",
     "iopub.status.busy": "2023-09-24T05:17:23.083776Z",
     "iopub.status.idle": "2023-09-24T05:17:24.007437Z",
     "shell.execute_reply": "2023-09-24T05:17:24.006411Z",
     "shell.execute_reply.started": "2023-09-24T05:17:23.084395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input English sentence: and so i get angry and i get pissed\n",
      "Actual Hindi Translation:  क्यों के ये बात पे मुझे बहोत ही अधिक ग़ुस्सा आता है \n",
      "Predicted Hindi Translation:  आज इस के मेरी हूँ पिछले मेरी मेरी मेरी मेरी मेरी\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T05:17:24.010637Z",
     "iopub.status.busy": "2023-09-24T05:17:24.010195Z",
     "iopub.status.idle": "2023-09-24T05:17:24.728589Z",
     "shell.execute_reply": "2023-09-24T05:17:24.727540Z",
     "shell.execute_reply.started": "2023-09-24T05:17:24.010601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input English sentence: who is very interested in success i really want to be successful\n",
      "Actual Hindi Translation:  जो सफलता में बहुत रूचि लेते है मैं वास्तव में सफल बनना चाहता हूँ \n",
      "Predicted Hindi Translation:  जो मेरे मेरे मैं मैं मैंने मैंने मैंने मैंने म\n"
     ]
    }
   ],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
